{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Idea: People tend to use bikes more on weekdays than weekends\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# original \n",
    "##### Null Hypothesis: The proportion of people that bike during the weekends is more or the same to the proportion of people that bike on weekdays\n",
    "### $h_0$ : $\\dfrac{riders_{weekday}}{riders_{total}} \\leqslant  \\dfrac{riders_{weekend}}{riders_{total}}$\n",
    "\n",
    "##### Alternative Hypothesis: The propportion of people that bike during the weekends is less than the proportion of people that bike on weekdays \n",
    "### $h_1$ : $\\dfrac{riders_{weekday}}{riders_{total}} >\\dfrac{riders_{weekend}}{riders_{total}}$\n",
    "\n",
    "## I've modified my hypothesis to incorporate suggestions based from Sarah's comments (sj909)\n",
    "### Null Hypothesis: The average amount of bike riders during the weekends is more or the same to the average amount of bike riders that bike on weekdays\n",
    "### $h_0$ : $\\mu_{weekday} \\leqslant \\mu_{weekend}$\n",
    "\n",
    "### Alternative Hypothesis: The average amount of bike riders during the weekends is less than the average amount of bike riders that bike on weekdays\n",
    "### $h_1$ : $\\mu_{weekday} > \\mu_{weekend}$\n",
    "\n",
    "### I set signifiance level for $\\alpha = 0.05$\n",
    "\n",
    "Now i import package and other important helper functions.<br>\n",
    "be advised i used the following packages that may not be in your default environment <br>\n",
    "dateutil<br>\n",
    "requests<br>\n",
    "zipfile<br>\n",
    "io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#/home/pui_user/PUI2018_msm796/HW4_msm796\n",
    "#declare libraries\n",
    "try:\n",
    "    import urllib2 as urllib\n",
    "except ImportError:\n",
    "    import urllib.request as urllib\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta #DOWNLOAD THIS PACKAGE#\n",
    "import os\n",
    "import requests #DOWNLOAD THIS PACKAGE#\n",
    "import zipfile #DOWNLOAD THIS PACKAGE#\n",
    "import io #DOWNLOAD THIS PACKAGE#\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess as sp\n",
    "import os\n",
    "\n",
    "#library#\n",
    "    \n",
    "#declare parameters\n",
    "puidata = os.getenv(\"PUIDATA\")\n",
    "if puidata is None:\n",
    "    os.environ[\"PUIDATA\"] = \"%s/PUIdata\"%os.getenv(\"HOME\")\n",
    "    puidata = os.getenv(\"PUIDATA\")\n",
    "\n",
    "#declare helper functions\n",
    "def download_citibike_data(yearstart,yearend,monthstart,monthend,output_path):\n",
    "    '''\n",
    "    change log:\n",
    "    \n",
    "    version 1.0 - Downloads citibike datasets zip files and unzips them. does checking if file already\n",
    "    exists in path. currently has no input error handling logic.\n",
    "    ---------------------------------------------------------------------------------------------\n",
    "    Parameters:\n",
    "    name - type - description\n",
    "    yearstart - <int> - refers to the year where you want your download to start\n",
    "    yearend - <int> - refers to the year where you want your download to start\n",
    "    monthstart - <int> - refers to the month ssociated with yearstart where you want your download to start\n",
    "    monthend - <int> - refers to the month associated with yearend where you want your download to start\n",
    "    outputpath - <str> - refers to location where you want to dump the csv files\n",
    "    \n",
    "    example usage:\n",
    "    download_citibike_data(2013,2018,6,8,puidata)\n",
    "    - this downloads the citibike datasets from June 2013 to August 2018. Files will be unzipped at\n",
    "    the puidata location.\n",
    "    \n",
    "    required libraries:\n",
    "    datautil - required for year & month generation\n",
    "    requests - for downloading the zip file\n",
    "    zipfile - to unzip the file\n",
    "    io - to read binary data and give it to zipfile; effectly keeping the entire process in memory\n",
    "    '''\n",
    "    #might include in error handling in the future for incorrect input\n",
    "    curr_date = start_date=datetime.datetime(yearstart,monthstart,1).date()\n",
    "    end_date=datetime.datetime(yearend,monthend,1).date()\n",
    "    year_month=[start_date.strftime('%Y%m')]\n",
    "    base_citi_url='https://s3.amazonaws.com/tripdata/'\n",
    "    while curr_date < end_date:\n",
    "        curr_date += relativedelta(months=1)\n",
    "        year_month.append(curr_date.strftime('%Y%m'))\n",
    "    for x in year_month:\n",
    "    #need to change logic as csv filename convention isn't done properly#\n",
    "    #will just base on dates found in directory#\n",
    "        filename=x+\"-citibike-tripdata.csv\"\n",
    "        if os.path.isfile(output_path+\"/\"+filename)==True:\n",
    "            print(\"{} already exists!\".format(filename))\n",
    "        else:\n",
    "            print(\"Downloading {}\".format(filename))\n",
    "            year=int(x[:4])\n",
    "            if year>=2017:\n",
    "                ending=\".csv.zip\"\n",
    "            else:\n",
    "                ending=\".zip\"\n",
    "            url=base_citi_url+x+\"-citibike-tripdata\"+ending\n",
    "            r = requests.get(url, stream=True)\n",
    "            z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "            z.extractall(output_path)\n",
    "            \n",
    "def append_all_citi_bike_data(input_path):\n",
    "    '''\n",
    "    developer's notes:\n",
    "    please refactor me! thanks!\n",
    "    change log:\n",
    "    \n",
    "    version 1.0 -currently has no input error handling logic or checking if file exists.\n",
    "\n",
    "    Parameters:\n",
    "    name - type - description\n",
    "    \n",
    "    input_path - <str> - location where the csv files are stored\n",
    "    -Naively appends all files into one superfile\n",
    "    \n",
    "    required libraries:\n",
    "    pandas - the output will be a dataframe, also used to load the files\n",
    "    '''\n",
    "    #currently implementing\n",
    "    files_directory=os.listdir(input_path)\n",
    "    csv_files = [x for x in files_directory if (\".csv\" in x) & ((\"citi\" in x) | (\"Citi\" in x))]\n",
    "    super_csv = pd.concat([pd.io.parsers.read_csv(input_path+\"/\"+f,engine='c',memory_map=True,low_memory='dtype') for f in csv_files],sort=False)\n",
    "#    super_csv = pd.concat([pd.read_csv(input_path+\"/\"+f,engine='c',memory_map=True,low_memory='dtype') for f in csv_files])\n",
    "    return super_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I get all the 2016 data from citibike and then concatenate them into one dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201601-citibike-tripdata.csv already exists!\n",
      "201602-citibike-tripdata.csv already exists!\n",
      "201603-citibike-tripdata.csv already exists!\n",
      "201604-citibike-tripdata.csv already exists!\n",
      "201605-citibike-tripdata.csv already exists!\n",
      "201606-citibike-tripdata.csv already exists!\n",
      "201607-citibike-tripdata.csv already exists!\n",
      "201608-citibike-tripdata.csv already exists!\n",
      "201609-citibike-tripdata.csv already exists!\n",
      "201610-citibike-tripdata.csv already exists!\n",
      "201611-citibike-tripdata.csv already exists!\n",
      "201612-citibike-tripdata.csv already exists!\n"
     ]
    }
   ],
   "source": [
    "#downloads from beginning to latest available as of late September\n",
    "download_citibike_data(2016,2016,1,12,puidata)\n",
    "complete_set=append_all_citi_bike_data(puidata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#complete_set.to_csv(puidata+'/complete_bike_as_of_201808.csv')\n",
    "#complete_set.to_csv(puidata+'/complete_2016_bike.csv')\n",
    "#complete_set2=pd.read_csv(puidata+'/complete_2016_bike.csv',engine='c',memory_map=True,low_memory='dtype')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying the first five rows of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tripduration</th>\n",
       "      <th>starttime</th>\n",
       "      <th>stoptime</th>\n",
       "      <th>start station id</th>\n",
       "      <th>start station name</th>\n",
       "      <th>start station latitude</th>\n",
       "      <th>start station longitude</th>\n",
       "      <th>end station id</th>\n",
       "      <th>end station name</th>\n",
       "      <th>end station latitude</th>\n",
       "      <th>...</th>\n",
       "      <th>Start Station Latitude</th>\n",
       "      <th>Start Station Longitude</th>\n",
       "      <th>End Station ID</th>\n",
       "      <th>End Station Name</th>\n",
       "      <th>End Station Latitude</th>\n",
       "      <th>End Station Longitude</th>\n",
       "      <th>Bike ID</th>\n",
       "      <th>User Type</th>\n",
       "      <th>Birth Year</th>\n",
       "      <th>Gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>538.0</td>\n",
       "      <td>5/1/2016 00:00:03</td>\n",
       "      <td>5/1/2016 00:09:02</td>\n",
       "      <td>536.0</td>\n",
       "      <td>1 Ave &amp; E 30 St</td>\n",
       "      <td>40.741444</td>\n",
       "      <td>-73.975361</td>\n",
       "      <td>497.0</td>\n",
       "      <td>E 17 St &amp; Broadway</td>\n",
       "      <td>40.737050</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>224.0</td>\n",
       "      <td>5/1/2016 00:00:04</td>\n",
       "      <td>5/1/2016 00:03:49</td>\n",
       "      <td>361.0</td>\n",
       "      <td>Allen St &amp; Hester St</td>\n",
       "      <td>40.716059</td>\n",
       "      <td>-73.991908</td>\n",
       "      <td>340.0</td>\n",
       "      <td>Madison St &amp; Clinton St</td>\n",
       "      <td>40.712690</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>328.0</td>\n",
       "      <td>5/1/2016 00:00:14</td>\n",
       "      <td>5/1/2016 00:05:43</td>\n",
       "      <td>301.0</td>\n",
       "      <td>E 2 St &amp; Avenue B</td>\n",
       "      <td>40.722174</td>\n",
       "      <td>-73.983688</td>\n",
       "      <td>311.0</td>\n",
       "      <td>Norfolk St &amp; Broome St</td>\n",
       "      <td>40.717227</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1196.0</td>\n",
       "      <td>5/1/2016 00:00:20</td>\n",
       "      <td>5/1/2016 00:20:17</td>\n",
       "      <td>3141.0</td>\n",
       "      <td>1 Ave &amp; E 68 St</td>\n",
       "      <td>40.765005</td>\n",
       "      <td>-73.958185</td>\n",
       "      <td>237.0</td>\n",
       "      <td>E 11 St &amp; 2 Ave</td>\n",
       "      <td>40.730473</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>753.0</td>\n",
       "      <td>5/1/2016 00:00:26</td>\n",
       "      <td>5/1/2016 00:13:00</td>\n",
       "      <td>492.0</td>\n",
       "      <td>W 33 St &amp; 7 Ave</td>\n",
       "      <td>40.750200</td>\n",
       "      <td>-73.990931</td>\n",
       "      <td>228.0</td>\n",
       "      <td>E 48 St &amp; 3 Ave</td>\n",
       "      <td>40.754601</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   tripduration          starttime           stoptime  start station id  \\\n",
       "0         538.0  5/1/2016 00:00:03  5/1/2016 00:09:02             536.0   \n",
       "1         224.0  5/1/2016 00:00:04  5/1/2016 00:03:49             361.0   \n",
       "2         328.0  5/1/2016 00:00:14  5/1/2016 00:05:43             301.0   \n",
       "3        1196.0  5/1/2016 00:00:20  5/1/2016 00:20:17            3141.0   \n",
       "4         753.0  5/1/2016 00:00:26  5/1/2016 00:13:00             492.0   \n",
       "\n",
       "     start station name  start station latitude  start station longitude  \\\n",
       "0       1 Ave & E 30 St               40.741444               -73.975361   \n",
       "1  Allen St & Hester St               40.716059               -73.991908   \n",
       "2     E 2 St & Avenue B               40.722174               -73.983688   \n",
       "3       1 Ave & E 68 St               40.765005               -73.958185   \n",
       "4       W 33 St & 7 Ave               40.750200               -73.990931   \n",
       "\n",
       "   end station id         end station name  end station latitude  ...    \\\n",
       "0           497.0       E 17 St & Broadway             40.737050  ...     \n",
       "1           340.0  Madison St & Clinton St             40.712690  ...     \n",
       "2           311.0   Norfolk St & Broome St             40.717227  ...     \n",
       "3           237.0          E 11 St & 2 Ave             40.730473  ...     \n",
       "4           228.0          E 48 St & 3 Ave             40.754601  ...     \n",
       "\n",
       "   Start Station Latitude  Start Station Longitude End Station ID  \\\n",
       "0                     NaN                      NaN            NaN   \n",
       "1                     NaN                      NaN            NaN   \n",
       "2                     NaN                      NaN            NaN   \n",
       "3                     NaN                      NaN            NaN   \n",
       "4                     NaN                      NaN            NaN   \n",
       "\n",
       "   End Station Name  End Station Latitude  End Station Longitude Bike ID  \\\n",
       "0               NaN                   NaN                    NaN     NaN   \n",
       "1               NaN                   NaN                    NaN     NaN   \n",
       "2               NaN                   NaN                    NaN     NaN   \n",
       "3               NaN                   NaN                    NaN     NaN   \n",
       "4               NaN                   NaN                    NaN     NaN   \n",
       "\n",
       "  User Type  Birth Year Gender  \n",
       "0       NaN         NaN    NaN  \n",
       "1       NaN         NaN    NaN  \n",
       "2       NaN         NaN    NaN  \n",
       "3       NaN         NaN    NaN  \n",
       "4       NaN         NaN    NaN  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I generate the list of columns before i reduced the number of columns of the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['tripduration', 'starttime', 'stoptime', 'start station id',\n",
       "       'start station name', 'start station latitude',\n",
       "       'start station longitude', 'end station id', 'end station name',\n",
       "       'end station latitude', 'end station longitude', 'bikeid',\n",
       "       'usertype', 'birth year', 'gender', 'Trip Duration', 'Start Time',\n",
       "       'Stop Time', 'Start Station ID', 'Start Station Name',\n",
       "       'Start Station Latitude', 'Start Station Longitude',\n",
       "       'End Station ID', 'End Station Name', 'End Station Latitude',\n",
       "       'End Station Longitude', 'Bike ID', 'User Type', 'Birth Year',\n",
       "       'Gender'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_set.columns.get_values()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since the phenomenon i want to investigate only requires that information regarding days, i only keep starttime & stoptime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols=[x for x in complete_set.columns.get_values() if x not in ['starttime','stoptime']]\n",
    "complete_set2=complete_set.drop(drop_cols,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Then i display my first 10 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_set2.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But we're curious whether or not there are more users during weekdays vs weekends, relatively speaking, so let's derive some days from our remaining columns. So first we remove rows with missing entries for our datetime fields because we cannot use them for this investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_set3 = complete_set2.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's now derive our days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_set3['day_start'] = complete_set3['starttime'].apply(lambda x : datetime.datetime.strptime(x, \"%m/%d/%Y %H:%M:%S\")).apply(lambda x: x.strftime('%A'))\n",
    "complete_set3['day_end'] = complete_set3['stoptime'].apply(lambda x : datetime.datetime.strptime(x, \"%m/%d/%Y %H:%M:%S\")).apply(lambda x: x.strftime('%A'))\n",
    "#complete_set3['day_start'] = complete_set3['starttime'].astype('datetime64[ns]').apply(lambda x: x.strftime('%A'))\n",
    "#complete_set3['day_end'] = complete_set3['stoptime'].astype('datetime64[ns]').apply(lambda x: x.strftime('%A'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## So now we have our days. But let's check if there are situations when some rides cross over midnight so that we can know if we can be indifferent of the variable of choice to describe our weekdays and weekends.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_set3.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_set3[complete_set3['day_start']!=complete_set3['day_end']].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It appears we have a set of observations that start and end trip at different days. Since we're looking into how the day falls under a weekend or weekday affects ridership, then we should use the day when the ride begins as our basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekend=['Saturday','Sunday']\n",
    "complete_set3['part_of_week']=complete_set3['day_start'].apply(lambda x: 'Weekend' if x in weekend else 'Weekday')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_set3.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's plot our counts per day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,10))\n",
    "complete_set3.day_start.value_counts().plot(kind = 'bar',rot=0)\n",
    "plt.xlabel(\"Day of week\",fontsize=18)\n",
    "plt.ylabel(\"Count\",fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Based on the bar graph, we get a general sense that weekdays will tend to have more rides than weekends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of weekdays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "complete_set3[complete_set3['part_of_week']=='Weekday'].groupby(['day_start'])['part_of_week'].count().plot(kind='bar',rot=0)\n",
    "plt.xlabel(\"Day of week\",fontsize=18)\n",
    "plt.ylabel(\"Count\",fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 2: We're dealing with a categorical distribution; a more generalized form of Bernoulli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distribution of weekends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "complete_set3[complete_set3['part_of_week']=='Weekend'].groupby(['day_start'])['part_of_week'].count().plot(kind='bar',rot=0)\n",
    "plt.xlabel(\"Day of week\",fontsize=18)\n",
    "plt.ylabel(\"Count\",fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3: We're dealing with a Bernoulli distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# But really, we more interested with the Distribution by part of week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "complete_set3.groupby(['part_of_week'])['day_start'].count().plot(kind='bar',rot=0)\n",
    "plt.xlabel(\"Day of week\",fontsize=18)\n",
    "plt.ylabel(\"Count\",fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Figure 3: We're dealing with a Bernoulli distribution\n",
    "## But naturally, by comparing them with counts is inappropriate. You could come up with a misleading conclusion with the data. There are five days in a weekdays and two days in weekends. So let's get the average ridership during weekdays and weekends, then and also adjust them by normalizing them by their respective Standard Deviation to get a sense on comparing them if they were in the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_wked = complete_set3[complete_set3['part_of_week']=='Weekend'].groupby(['day_start'])['part_of_week'].count().mean()\n",
    "mean_wkdy = complete_set3[complete_set3['part_of_week']=='Weekday'].groupby(['day_start'])['part_of_week'].count().mean()\n",
    "std_wked = complete_set3[complete_set3['part_of_week']=='Weekend'].groupby(['day_start'])['part_of_week'].count().std()\n",
    "std_wkdy = complete_set3[complete_set3['part_of_week']=='Weekday'].groupby(['day_start'])['part_of_week'].count().std()\n",
    "\n",
    "print(\"sample mean ridership for weekends: {:,} ,sample mean ridership for weekdays: {:,}\".format(mean_wked,mean_wkdy))\n",
    "print(\"Standard Error ridership for weekends: {} , Standard Error ridership for weekdays: {}\".format(std_wked,std_wkdy))\n",
    "print(\"the normalized sample mean ridership for weekends: {} ,the normalized sample mean ridership for weekdays: {}\".format(mean_wked/std_wked,mean_wkdy/std_wkdy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
