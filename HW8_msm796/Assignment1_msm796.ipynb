{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Anaconda3-5.0.0-Linux-x86_64/envs/PUI2016_Python3/lib/python3.5/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "#declare libraries\n",
    "try:\n",
    "    import urllib2 as urllib\n",
    "except ImportError:\n",
    "    import urllib.request as urllib\n",
    "import datetime\n",
    "from dateutil.relativedelta import relativedelta #DOWNLOAD THIS PACKAGE#\n",
    "import os\n",
    "import requests #DOWNLOAD THIS PACKAGE#\n",
    "import zipfile #DOWNLOAD THIS PACKAGE#\n",
    "import io #DOWNLOAD THIS PACKAGE#\n",
    "import pandas as pd\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess as sp\n",
    "import os\n",
    "import time\n",
    "import pylab as pl\n",
    "import scipy.stats\n",
    "from shapely.geometry import Point\n",
    "import statsmodels.formula.api as smf\n",
    "#import geopandas as gpd\n",
    "import random\n",
    "import json\n",
    "from fiona.crs import from_epsg\n",
    "import pysal as ps\n",
    "import math\n",
    "import matplotlib.pylab as plt\n",
    "import seaborn as sbn\n",
    "%matplotlib inline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import preprocessing\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.model_selection import train_test_split\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn import datasets\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "puidata = os.getenv(\"PUIDATA\")\n",
    "if puidata is None:\n",
    "    os.environ[\"PUIDATA\"] = \"%s/PUIdata\"%os.getenv(\"HOME\")\n",
    "    puidata = os.getenv(\"PUIDATA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 1366M  100 1366M    0     0  74.4M      0  0:00:18  0:00:18 --:--:-- 65.1M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 63.1M  100 63.1M    0     0  61.4M      0  0:00:01  0:00:01 --:--:-- 61.4M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100  733M  100  733M    0     0  70.6M      0  0:00:10  0:00:10 --:--:-- 75.6M\n",
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 12322  100 12322    0     0  87381      0 --:--:-- --:--:-- --:--:-- 88014\n"
     ]
    }
   ],
   "source": [
    "#i got these links from http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml\n",
    "# essentially these are just the trip level data for hire vehicles, green and yellow taxi datasets for June 2018\n",
    "#download data and place them into the PUIdata folder\n",
    "!curl https://s3.amazonaws.com/nyc-tlc/trip+data/fhv_tripdata_2018-06.csv > ~/PUIdata/fhv_tripdata_2018-06.csv\n",
    "!curl https://s3.amazonaws.com/nyc-tlc/trip+data/green_tripdata_2018-06.csv > ~/PUIdata/green_tripdata_2018-06.csv\n",
    "!curl https://s3.amazonaws.com/nyc-tlc/trip+data/yellow_tripdata_2018-06.csv > ~/PUIdata/yellow_tripdata_2018-06.csv\n",
    "\n",
    "#lookup table related to taxi zones\n",
    "!curl https://s3.amazonaws.com/nyc-tlc/misc/taxi+_zone_lookup.csv > ~/PUIdata/taxi+_zone_lookup.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fix to remove empty line at line 2 of yellow_trip_data\n",
    "!sed -i '2d' ~/PUIdata/yellow_tripdata_2018-06.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download shapefiles related to taxizones \n",
    "def dl_unzip(url,output_path):\n",
    "    '''\n",
    "    description: downloads a zipfile, given a url address and unpacks it at provided location\n",
    "    ----------------------------------------------------------------------------------\n",
    "    Parameters - Parameter Type - Description - Example input\n",
    "    1.) url - <string> - refers url address for the zipfile - \"http://www.lalaland.com/goose.zip\"\n",
    "    2.) output_path - <string> - refers to the working directory where you want to unpack your file - \"~\\sebs_bar\"\n",
    "    ----------------------------------------------------------------------------------\n",
    "    room for improvement\n",
    "    1.) error handling\n",
    "    2.) returns status\n",
    "    \n",
    "    has dependencies on the following packages\n",
    "    requests\n",
    "    zipfile\n",
    "    ----------------------------------------------------------------------------------\n",
    "    Example usage:\n",
    "    dl_unzip(\"http://www.lalaland.com/goose.zip\",\"~/sebs_bar\")\n",
    "    '''    \n",
    "    r = requests.get(url, stream=True)\n",
    "    z = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "    z.extractall(output_path)\n",
    "    \n",
    "dl_unzip(\"https://s3.amazonaws.com/nyc-tlc/misc/taxi_zones.zip\",puidata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow = pd.read_csv('~/PUIdata/fhv_tripdata_2018-06.csv')\n",
    "green = pd.read_csv('~/PUIdata/green_tripdata_2018-06.csv')\n",
    "FHV = pd.read_csv('~/PUIdata/yellow_tripdata_2018-06.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yellow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "green.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FHV.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PUI2016_Python3",
   "language": "python",
   "name": "pui2016_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
